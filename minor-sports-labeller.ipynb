{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/ik/Data/'\n",
    "\n",
    "class StringNormalizer(object):\n",
    "    \"\"\"\n",
    "    normalise a string\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        # english stopwords\n",
    "        self.STOP_WORDS = {line.strip() for line in open(DATA_DIR + 'stopwords' + '/english_stopwords_nltk.txt', 'r').readlines() \n",
    "                           if line.strip()} \n",
    "        # country abbreviation according to the UN(!) standards\n",
    "        self.COUNTRY_ABBRS = pd.read_csv(DATA_DIR + 'country-abbreviations' + '/country_abbreviations.txt', header=None,\n",
    "                                        names=\"country abbr1 abbr2\".split())\n",
    "        self.MISC_ABBRS = {\"champs\": \"championships\", \"champ\": \"championship\", \"intl\": \"international\", \n",
    "                           \"int\": \"international\", \"aust\": \"australian\"}\n",
    "        self.COUNTRY_ALT = {\"united states\": [\"usa\", \"united states of america\", \"us\"],\n",
    "                              \"russia\": [\"russian federation\"], \"chinese taipei\": [\"taiwan\"], \"macedonia\": [\"fyrom\"],\n",
    "                                  \"netherlands\": [\"holland\"]}\n",
    "\n",
    "    def normalize(self, s):\n",
    "        \n",
    "        # check if s is really a string\n",
    "        assert isinstance(s, str), 'you are trying to normalise something that is NOT a string!'\n",
    "        # note s might still be empty but that's fine as we take care of it next\n",
    "        _ = \"\".join([ch.lower() for ch in s if ch.isalnum() or ch.isspace()])\n",
    "        # remove stopwords\n",
    "        _ = \" \".join([w for w in _.split() if w not in self.STOP_WORDS])\n",
    "        # unfold \"other\" abbreviations\n",
    "        _  = \" \".join([self.MISC_ABBRS[w] if w in self.MISC_ABBRS else w for w in _.split()])\n",
    "        # country alternative names\n",
    "        _ = ' ' + _ + ' '\n",
    "        for country in self.COUNTRY_ALT:\n",
    "            for alt_names in self.COUNTRY_ALT[country]:\n",
    "                _ = _.replace(' ' + alt_names  + ' ', ' ' + country + ' ')     \n",
    "        return _\n",
    "\n",
    "class SportIdentifier(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.sids = json.load(open(DATA_DIR + 'sports/' + 'sports-identifiers/' + \"sports-identifiers-27092017.json\",\"r\"))\n",
    "        print(\"supported sports: {}\".format(len(self.sids)))\n",
    "        print(\" \".join([\"{}. {}\".format(i, sport) for i, sport in enumerate(sorted([sp for sp in self.sids]), 1)]))\n",
    "        \n",
    "        self.SHOW_SYNS = set(\"\"\"appearance display fair pageant parade presentation program spectacle expo exposition\n",
    "                    fanfare fireworks grandstand occurrence pageantry panoply representation shine showboat\n",
    "                    showing sight splash view anniversary commemoration competition fair feast gala\n",
    "                    holiday carnival entertainment festivities fete fiesta jubilee merrymaking trear\n",
    "                    bazar celebration display exhibit festival gala market pageant\n",
    "                    show centennial occasion spectacle act concert portrayal production burlesque\n",
    "                    ceremony gig matinee recital rehearsal revue rigmarole rite special\n",
    "                    spectacle stunt stage circus\"\"\".split())\n",
    "        self.MEAL_SYNS = set(\"breakfast lunch dinner banquet feast supper\".split())\n",
    "        \n",
    "        self.NONSPORT_TYPES = {\"theatre\", \"theater\", \"movie\", \"cinema\", \"circus\", \"opera\", \"musical\", \n",
    "                              \"exhibition\", \"market\", \"event\", \"encounter\", \"night\", \"casino\", \"comedy\", \n",
    "                              \"trivia\", \"charity\", \"fundraiser\", \"museum\", \"donation\", \"parking\"}\n",
    "        \n",
    "        self.norm = StringNormalizer()\n",
    "    \n",
    "    \n",
    "    def _find_identifiers(self, s):\n",
    "        \n",
    "        comps = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for sport in self.sids:\n",
    "            # competitions\n",
    "            try:\n",
    "                for gc in self.sids[sport][\"competitions\"][\"generic\"]:\n",
    "                    if self.norm.normalize(gc) in self.norm.normalize(s):\n",
    "                        comps[sport][\"generic\" + \"_\" + 'comps'] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                for gc in self.sids[sport][\"competitions\"][\"nongeneric\"]:\n",
    "                    if self.norm.normalize(gc) in self.norm.normalize(s):\n",
    "                        comps[sport][\"nongeneric\" + \"_\" + 'comps'] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # nicknames\n",
    "            if \"team_nicknames\" in self.sids[sport]:\n",
    "                for gc in self.sids[sport][\"team_nicknames\"]:\n",
    "                    if self.norm.normalize(gc) in self.norm.normalize(s):\n",
    "                        comps[sport][\"team_nicknames\"] += 1\n",
    "            # sport names\n",
    "            if \"(\" in sport:\n",
    "                sport_names = [sport_name.strip() for sport_name in sport.replace(\")\", \"\").split(\"(\")]\n",
    "            else:\n",
    "                sport_names = [sport]\n",
    "            for sp in sport_names:\n",
    "                if self.norm.normalize(sp) in self.norm.normalize(s):\n",
    "                    comps[sport][\"sport_name\"] += 1\n",
    "            # abbreviations\n",
    "            if \"abbreviations\" in self.sids[sport]:\n",
    "                cmn_abbrs = set(self.sids[sport][\"abbreviations\"]) & set(s.split())\n",
    "                if cmn_abbrs:\n",
    "                    comps[sport]['abbreviations'] = len(cmn_abbrs)\n",
    "            # sponsors\n",
    "            if \"sponsors\" in self.sids[sport]:\n",
    "                for sponsor in self.sids[sport][\"sponsors\"]:\n",
    "                    if self.norm.normalize(sponsor) in self.norm.normalize(s):\n",
    "                        comps[sport]['sponsors'] += 1\n",
    "            # participants\n",
    "            if \"key_participants\" in self.sids[sport]:\n",
    "                np = 0\n",
    "                for participant in self.sids[sport][\"key_participants\"]:\n",
    "                    if self.norm.normalize(participant) in self.norm.normalize(s):\n",
    "                        np += 1\n",
    "                if np > 0:\n",
    "                    comps[sport]['key_participantss'] = np\n",
    "                    \n",
    "        return comps\n",
    "    \n",
    "    \n",
    "    def pick_sport(self, s):\n",
    "        \n",
    "        # if any show synonym or non-sport word found, it's clearly not a sport\n",
    "        words_in_descr = set(s.lower().split())\n",
    "        \n",
    "        if (self.SHOW_SYNS | self.NONSPORT_TYPES) & words_in_descr:\n",
    "            return None\n",
    "        \n",
    "        # now if there's a chance that this is sport...\n",
    "        self.d = self._find_identifiers(s)\n",
    "        \n",
    "        for sport in self.d:\n",
    "            # first, check for the specific compatitions\n",
    "            if \"nongeneric_comps\" in self.d[sport]:\n",
    "                if {\"abbreviations\", \"key_participants\", \"sport_name\", \"team_nicknames\"} & set(self.d[sport]):\n",
    "                    return sport\n",
    "                else:\n",
    "                    return None\n",
    "            if \"generic_comps\" in self.d[sport]:\n",
    "                try:\n",
    "                    if (self.d[sport][\"key_participants\"] == 2):\n",
    "                        return sport\n",
    "                except:\n",
    "                    if {\"abbreviations\", \"sport_name\", \"team_nicknames\"} & set(self.d[sport]):\n",
    "                        return sport\n",
    "                    else:\n",
    "                        return None\n",
    "            if (\"abbreviations\" in self.d[sport]) or (\"sponsors\" in self.d[sport]):\n",
    "                 try:\n",
    "                    if (self.d[sport][\"key_participants\"] == 2):\n",
    "                        return sport\n",
    "                 except:\n",
    "                    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total events to check: 397753\n"
     ]
    }
   ],
   "source": [
    "tkt_events = pd.read_csv(DATA_DIR + 'events/' + 'all-events-18092017.csv.gz', encoding='latin-1')\n",
    "print(\"total events to check: {}\".format(len(tkt_events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported sports: 44\n",
      "1. afl (australian football league) 2. archery 3. badminton 4. baseball 5. bodybuilding 6. boxing 7. bullriding 8. canoeing 9. cricket 10. crossfit 11. cycling 12. dancesport 13. darts 14. diving 15. equestrian 16. fencing 17. golf 18. gridiron (american football) 19. gymnastics 20. handball 21. hockey 22. ice skating 23. karate 24. kickboxing 25. lacrosse 26. motorcycle racing 27. nrl (national rugby league) 28. pentathlon 29. rowing 30. rugby union 31. sailing 32. shooting 33. skating 34. softball 35. squash 36. supercars 37. swimming 38. table tennis 39. taekwondo 40. triathlon 41. volleyball 42. water polo 43. weightlifting 44. wrestling\n"
     ]
    }
   ],
   "source": [
    "si = SportIdentifier()\n",
    "\n",
    "t0 = time.time()\n",
    "tkt_events[\"is_sport\"] = tkt_events.description.apply(lambda x: si.pick_sport(x))\n",
    "print(\"elapsed time: {:.0f} m {:.0f} s\".format(*divmod(time.time() - t0, 60)))\n",
    "tkt_events[tkt_events.is_sport.notnull()].to_csv(\"all-sport-events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = pd.read_csv(\"all-sport-events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(sports.is_sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
