{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/ik/Data/'\n",
    "\n",
    "class StringNormalizer(object):\n",
    "    \"\"\"\n",
    "    normalise a string\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        # english stopwords\n",
    "        self.STOP_WORDS = {line.strip() for line in open(DATA_DIR + 'stopwords' + '/english_stopwords_nltk.txt', 'r').readlines() \n",
    "                           if line.strip()} \n",
    "        # country abbreviation according to the UN(!) standards\n",
    "        self.COUNTRY_ABBRS = pd.read_csv(DATA_DIR + 'country-abbreviations' + '/country_abbreviations.txt', header=None,\n",
    "                                        names=\"country abbr1 abbr2\".split())\n",
    "        self.MISC_ABBRS = {\"champs\": \"championships\", \"champ\": \"championship\", \"intl\": \"international\", \n",
    "                           \"int\": \"international\", \"aust\": \"australian\"}\n",
    "        self.COUNTRY_ALT = {\"united states\": [\"usa\", \"united states of america\", \"us\"],\n",
    "                              \"russia\": [\"russian federation\"], \"chinese taipei\": [\"taiwan\"], \"macedonia\": [\"fyrom\"],\n",
    "                                  \"netherlands\": [\"holland\"]}\n",
    "\n",
    "    def normalize(self, s):\n",
    "        \n",
    "        # check if s is really a string\n",
    "        assert isinstance(s, str), 'you are trying to normalise something that is NOT a string!'\n",
    "        # note s might still be empty but that's fine as we take care of it next\n",
    "        _ = \"\".join([ch.lower() for ch in s if ch.isalnum() or ch.isspace()])\n",
    "        # remove stopwords\n",
    "        _ = \" \".join([w for w in _.split() if w not in self.STOP_WORDS])\n",
    "        # unfold \"other\" abbreviations\n",
    "        _  = \" \".join([self.MISC_ABBRS[w] if w in self.MISC_ABBRS else w for w in _.split()])\n",
    "        # country alternative names\n",
    "        for country in self.COUNTRY_ALT:\n",
    "            for alt_names in self.COUNTRY_ALT[country]:\n",
    "                _ = (' ' + _ + ' ').replace(' ' + alt_names  + ' ', ' ' + country + ' ')     \n",
    "        return _\n",
    "\n",
    "class SportIdentifier(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.sids = json.load(open(DATA_DIR + 'sports/' + 'sports-identifiers/' + \"sports-identifiers-21092017.json\",\"r\"))\n",
    "        print(\"supported sports: {}\".format(len(self.sids)))\n",
    "        print(\" \".join([\"{}. {}\".format(i, sport) for i, sport in enumerate(sorted([sp for sp in self.sids]), 1)]))\n",
    "\n",
    "        # feature weights\n",
    "        self.w = {\"nongeneric_comps\": lambda _: 1,\n",
    "                  \"generic_comps\": lambda _: _*0.25, # so 1 generic conmp gets 0.25, 2 get 0.5\n",
    "                  \"sport_name\": lambda _: 1, \"teams\": lambda _:  _*0.2,  # 1 team only 0.2, two get 1\n",
    "                     \"spons\": lambda _: 0.5, \"abbreviations\": lambda _: _}\n",
    "        \n",
    "        self.SHOW_SYNS = set(\"\"\"appearance display fair pageant parade presentation program spectacle expo exposition\n",
    "                    fanfare fireworks grandstand occurrence pageantry panoply representation shine showboat\n",
    "                    showing sight splash view anniversary commemoration competition fair feast gala\n",
    "                    holiday carnival entertainment festivities fete fiesta jubilee merrymaking trear\n",
    "                    bazar celebration display exhibit festival gala market pageant\n",
    "                    show centennial occasion spectacle act concert portrayal production burlesque\n",
    "                    ceremony gig matinee recital rehearsal revue rigmarole rite special\n",
    "                    spectacle stunt stage circus\"\"\".split())\n",
    "        \n",
    "        self.NONSPORT_TYPES = {\"theatre\", \"theater\", \"movie\", \"cinema\", \"circus\", \"opera\", \"musical\", \n",
    "                              \"exhibition\", \"market\", \"event\", \"encounter\", \"night\", \"casino\", \"comedy\", \n",
    "                              \"trivia\", \"charity\", \"fundraiser\", \"museum\"}\n",
    "        \n",
    "        self.norm = StringNormalizer()\n",
    "    \n",
    "    \n",
    "    def _find_identifiers(self, s):\n",
    "        \n",
    "        comps = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for sport in self.sids:\n",
    "            # competitions\n",
    "            for ckind in [\"generic\", \"nongeneric\"]:\n",
    "                for gc in self.sids[sport][\"competitions\"][ckind]:\n",
    "                    if self.norm.normalize(gc) in self.norm.normalize(s):\n",
    "                        comps[sport][ckind + \"_\" + 'comps'] += 1\n",
    "            # nicknames\n",
    "            if \"team_nicknames\" in self.sids[sport]:\n",
    "                for gc in self.sids[sport][\"team_nicknames\"]:\n",
    "                    if self.norm.normalize(gc) in self.norm.normalize(s):\n",
    "                        comps[sport][\"team_nicknames\"] += 1\n",
    "            # sport names\n",
    "            if \"(\" in sport:\n",
    "                sport_names = [sport_name.strip() for sport_name in sport.replace(\")\", \"\").split(\"(\")]\n",
    "            else:\n",
    "                sport_names = [sport]\n",
    "            for sp in sport_names:\n",
    "                if self.norm.normalize(sp) in self.norm.normalize(s):\n",
    "                    comps[sport][\"sport_name\"] += 1\n",
    "            # abbreviations\n",
    "            if \"abbreviations\" in self.sids[sport]:\n",
    "                cmn_abbrs = set(self.sids[sport][\"abbreviations\"]) & set(s.split())\n",
    "                if cmn_abbrs:\n",
    "                    comps[sport]['abbreviations'] = len(cmn_abbrs)\n",
    "            # sponsors\n",
    "            if \"sponsors\" in self.sids[sport]:\n",
    "                for sponsor in self.sids[sport][\"sponsors\"]:\n",
    "                    if self.norm.normalize(sponsor) in self.norm.normalize(s):\n",
    "                        comps[sport]['spons'] += 1\n",
    "            # participants\n",
    "            if \"key_participants\" in self.sids[sport]:\n",
    "                np = 0\n",
    "                for participant in self.sids[sport][\"key_participants\"]:\n",
    "                    if self.norm.normalize(participant) in self.norm.normalize(s):\n",
    "                        np += 1\n",
    "                if np > 0:\n",
    "                    comps[sport]['teams'] = np\n",
    "                    \n",
    "        return comps\n",
    "    \n",
    "    \n",
    "    def pick_sport(self, s):\n",
    "        \n",
    "        # if any show synonym or non-sport word found, it's clearly not a sport\n",
    "        words_in_descr = set(s.lower().split())\n",
    "        \n",
    "        if (self.SHOW_SYNS | self.NONSPORT_TYPES) & words_in_descr:\n",
    "            return None\n",
    "        \n",
    "        # now if there's a chance that this is sport...\n",
    "        self.d = self._find_identifiers(s)\n",
    "        \n",
    "        for sport in self.d:\n",
    "            # first, check for the specific compatitions\n",
    "            if \"nongeneric_comps\" in self.d[sport]:\n",
    "                if ((\"abbreviations\" in self.d[sport]) or (\"key_participants\" in self.d[sport]) \n",
    "                or (\"sport_name\" in self.d[sport])):\n",
    "                    return sport\n",
    "            # 1 nickname and 1 participants\n",
    "            if (\"team_nicknames\" in self.d[sport]) and (\"key_participants\" in self.d[sport]):\n",
    "                return sport\n",
    "            # 2 participants and a generic competition\n",
    "            if (\"key_participants\" in self.d[sport]) and (\"generic_comps\" in self.d[sport]):\n",
    "                if (self.d[sport][\"key_participants\"] > 1) and (self.d[sport][\"generic_comps\"] > 1):\n",
    "                    return sport\n",
    "            # 1 abbreviation and a generic competition\n",
    "            if (\"abbreviations\" in self.d[sport]) and (\"generic_comps\" in self.d[sport]):\n",
    "                return sport\n",
    "            # sports name (if 1 word in sentence)\n",
    "            if \"sport_name\" in self.d[sport]:\n",
    "                if len(self.norm.normalize(s)) == 1:\n",
    "                    return sport\n",
    "                elif \"generic_comps\" in self.d[sport]:\n",
    "                    return sport      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkt_events = pd.read_csv(DATA_DIR + 'events/' + 'all-events-18092017.csv.gz', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown - - - - - - - - -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>unknown - - - - - - - - -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>r carlos nakai - iwaki auditorium   r. carlos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>karen schaupp - iwaki auditorium    karin scha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown - - - - - - - - -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                                        description\n",
       "0         1                          unknown - - - - - - - - -\n",
       "1         2                          unknown - - - - - - - - -\n",
       "2         3  r carlos nakai - iwaki auditorium   r. carlos ...\n",
       "3         4  karen schaupp - iwaki auditorium    karin scha...\n",
       "4         5                          unknown - - - - - - - - -"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkt_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported sports: 30\n",
      "1. badminton 2. baseball 3. bodybuilding 4. boxing 5. bullriding 6. cricket 7. crossfit 8. cycling 9. dancesport 10. darts 11. diving 12. equestrian 13. fencing 14. golf 15. gridiron (american football) 16. gymnastics 17. hockey 18. ice skating 19. karate 20. kickboxing 21. pentathlon 22. rowing 23. skating 24. squash 25. supercars 26. swimming 27. table tennis 28. volleyball 29. weightlifting 30. wrestling\n"
     ]
    }
   ],
   "source": [
    "si = SportIdentifier()\n",
    "import time\n",
    "t0 = time.time()\n",
    "tkt_events[\"is_sport\"] = tkt_events.loc[tkt_events.event_id.isin(range(20000)), \"description\"].apply(lambda x: si.pick_sport(x))\n",
    "print(\"elapsed time: {:.0f} m {:.0f} s\".format(*divmod(time.time() - t0, 60)))\n",
    "tkt_events[tkt_events.is_sport.notnull()]\n",
    "\n",
    "# print(\"sport: {}\".format(si.find_identifiers(\"big bash\").score_sports()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astor theatre season - prahran - melbourne  angelas ashes (m) sat 26 aug 2000 7:30pm   the astor theatre   the astor theatre   angelas ashes (m)     (2000)  sat 26 aug 2000 7:30pm']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkt_events.loc[tkt_events.event_id == 2209, \"description\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>abbr1</th>\n",
       "      <th>abbr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>af</td>\n",
       "      <td>afg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albania</td>\n",
       "      <td>al</td>\n",
       "      <td>alb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dz</td>\n",
       "      <td>dza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>as</td>\n",
       "      <td>asm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorra</td>\n",
       "      <td>ad</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angola</td>\n",
       "      <td>ao</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anguilla</td>\n",
       "      <td>ai</td>\n",
       "      <td>aia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>antarctica</td>\n",
       "      <td>aq</td>\n",
       "      <td>ata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>antigua and barbuda</td>\n",
       "      <td>ag</td>\n",
       "      <td>atg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>argentina</td>\n",
       "      <td>ar</td>\n",
       "      <td>arg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>armenia</td>\n",
       "      <td>am</td>\n",
       "      <td>arm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aruba</td>\n",
       "      <td>aw</td>\n",
       "      <td>abw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>australia</td>\n",
       "      <td>au</td>\n",
       "      <td>aus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>austria</td>\n",
       "      <td>at</td>\n",
       "      <td>aut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>az</td>\n",
       "      <td>aze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bahamas</td>\n",
       "      <td>bs</td>\n",
       "      <td>bhs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bahrain</td>\n",
       "      <td>bh</td>\n",
       "      <td>bhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bangladesh</td>\n",
       "      <td>bd</td>\n",
       "      <td>bgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>barbados</td>\n",
       "      <td>bb</td>\n",
       "      <td>brb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>belarus</td>\n",
       "      <td>by</td>\n",
       "      <td>blr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>belgium</td>\n",
       "      <td>be</td>\n",
       "      <td>bel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>belize</td>\n",
       "      <td>bz</td>\n",
       "      <td>blz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>benin</td>\n",
       "      <td>bj</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bermuda</td>\n",
       "      <td>bm</td>\n",
       "      <td>bmu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bhutan</td>\n",
       "      <td>bt</td>\n",
       "      <td>btn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bolivia</td>\n",
       "      <td>bo</td>\n",
       "      <td>bol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bonaire</td>\n",
       "      <td>bq</td>\n",
       "      <td>bes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bosnia and herzegovina</td>\n",
       "      <td>ba</td>\n",
       "      <td>bih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>botswana</td>\n",
       "      <td>bw</td>\n",
       "      <td>bwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bouvet island</td>\n",
       "      <td>bv</td>\n",
       "      <td>bvt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>united republic of tanzania</td>\n",
       "      <td>tz</td>\n",
       "      <td>tza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>thailand</td>\n",
       "      <td>th</td>\n",
       "      <td>tha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>timor-leste</td>\n",
       "      <td>tl</td>\n",
       "      <td>tls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>togo</td>\n",
       "      <td>tg</td>\n",
       "      <td>tgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tokelau</td>\n",
       "      <td>tk</td>\n",
       "      <td>tkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tonga</td>\n",
       "      <td>to</td>\n",
       "      <td>ton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>trinidad and tobago</td>\n",
       "      <td>tt</td>\n",
       "      <td>tto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tunisia</td>\n",
       "      <td>tn</td>\n",
       "      <td>tun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>turkey</td>\n",
       "      <td>tr</td>\n",
       "      <td>tur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>turkmenistan</td>\n",
       "      <td>tm</td>\n",
       "      <td>tkm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>turks and caicos islands</td>\n",
       "      <td>tc</td>\n",
       "      <td>tca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tuvalu</td>\n",
       "      <td>tv</td>\n",
       "      <td>tuv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>uganda</td>\n",
       "      <td>ug</td>\n",
       "      <td>uga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>ua</td>\n",
       "      <td>ukr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>united arab emirates</td>\n",
       "      <td>ae</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>united kingdom</td>\n",
       "      <td>gb</td>\n",
       "      <td>gbr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>united states minor outlying islands</td>\n",
       "      <td>um</td>\n",
       "      <td>umi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>uruguay</td>\n",
       "      <td>uy</td>\n",
       "      <td>ury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>uzbekistan</td>\n",
       "      <td>uz</td>\n",
       "      <td>uzb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>vanuatu</td>\n",
       "      <td>vu</td>\n",
       "      <td>vut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>venezuela</td>\n",
       "      <td>ve</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>viet nam</td>\n",
       "      <td>vn</td>\n",
       "      <td>vnm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>british virgin islands</td>\n",
       "      <td>vg</td>\n",
       "      <td>vgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>us virgin islands</td>\n",
       "      <td>vi</td>\n",
       "      <td>vir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>wallis and futuna</td>\n",
       "      <td>wf</td>\n",
       "      <td>wlf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>western sahara</td>\n",
       "      <td>eh</td>\n",
       "      <td>esh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>yemen</td>\n",
       "      <td>ye</td>\n",
       "      <td>yem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>zambia</td>\n",
       "      <td>zm</td>\n",
       "      <td>zmb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>zw</td>\n",
       "      <td>zwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  country abbr1 abbr2\n",
       "0                             afghanistan    af   afg\n",
       "1                                 albania    al   alb\n",
       "2                                 algeria    dz   dza\n",
       "3                          american samoa    as   asm\n",
       "4                                 andorra    ad   and\n",
       "5                                  angola    ao   ago\n",
       "6                                anguilla    ai   aia\n",
       "7                              antarctica    aq   ata\n",
       "8                     antigua and barbuda    ag   atg\n",
       "9                               argentina    ar   arg\n",
       "10                                armenia    am   arm\n",
       "11                                  aruba    aw   abw\n",
       "12                              australia    au   aus\n",
       "13                                austria    at   aut\n",
       "14                             azerbaijan    az   aze\n",
       "15                                bahamas    bs   bhs\n",
       "16                                bahrain    bh   bhr\n",
       "17                             bangladesh    bd   bgd\n",
       "18                               barbados    bb   brb\n",
       "19                                belarus    by   blr\n",
       "20                                belgium    be   bel\n",
       "21                                 belize    bz   blz\n",
       "22                                  benin    bj   ben\n",
       "23                                bermuda    bm   bmu\n",
       "24                                 bhutan    bt   btn\n",
       "25                                bolivia    bo   bol\n",
       "26                                bonaire    bq   bes\n",
       "27                 bosnia and herzegovina    ba   bih\n",
       "28                               botswana    bw   bwa\n",
       "29                          bouvet island    bv   bvt\n",
       "..                                    ...   ...   ...\n",
       "218           united republic of tanzania    tz   tza\n",
       "219                              thailand    th   tha\n",
       "220                           timor-leste    tl   tls\n",
       "221                                  togo    tg   tgo\n",
       "222                               tokelau    tk   tkl\n",
       "223                                 tonga    to   ton\n",
       "224                   trinidad and tobago    tt   tto\n",
       "225                               tunisia    tn   tun\n",
       "226                                turkey    tr   tur\n",
       "227                          turkmenistan    tm   tkm\n",
       "228              turks and caicos islands    tc   tca\n",
       "229                                tuvalu    tv   tuv\n",
       "230                                uganda    ug   uga\n",
       "231                               ukraine    ua   ukr\n",
       "232                  united arab emirates    ae   are\n",
       "233                        united kingdom    gb   gbr\n",
       "234                         united states    us   usa\n",
       "235  united states minor outlying islands    um   umi\n",
       "236                               uruguay    uy   ury\n",
       "237                            uzbekistan    uz   uzb\n",
       "238                               vanuatu    vu   vut\n",
       "239                             venezuela    ve   ven\n",
       "240                              viet nam    vn   vnm\n",
       "241                british virgin islands    vg   vgb\n",
       "242                     us virgin islands    vi   vir\n",
       "243                     wallis and futuna    wf   wlf\n",
       "244                        western sahara    eh   esh\n",
       "245                                 yemen    ye   yem\n",
       "246                                zambia    zm   zmb\n",
       "247                              zimbabwe    zw   zwe\n",
       "\n",
       "[248 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StringNormalizer().COUNTRY_ABBRS    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
